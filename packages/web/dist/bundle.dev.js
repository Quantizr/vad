/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory(require("onnxruntime-web"));
	else if(typeof define === 'function' && define.amd)
		define(["onnxruntime-web"], factory);
	else if(typeof exports === 'object')
		exports["vad"] = factory(require("onnxruntime-web"));
	else
		root["vad"] = factory(root["ort"]);
})(self, (__WEBPACK_EXTERNAL_MODULE_onnxruntime_web__) => {
return /******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "../../node_modules/custom-audio-node/audio-param.js":
/*!***********************************************************!*\
  !*** ../../node_modules/custom-audio-node/audio-param.js ***!
  \***********************************************************/
/***/ ((module) => {

eval("module.exports = function(audioContext, name, options){\n  // options: provider, target(s)\n\n  options = options || {}\n\n  var targets = options.targets\n\n  if (!targets && options.target){\n    targets = [options.target]\n  } else if (!targets){\n    targets = []\n  }\n\n  var param = Object.create(AudioParam.prototype, {\n    value: {\n      get: function(){\n        return param._lastValue\n      },\n      set: function(value){\n        value = param.fence(value)\n        param._lastValue = value\n        for (var i=0,l=targets.length;i<l;i++){\n          var target = targets[i]\n          target.value = value\n        }\n      }\n    },\n    defaultValue: {\n      get: function(){\n        return options.defaultValue\n      }\n    },\n    name: {\n      value: name,\n      writable: false\n    },\n    min: {\n      value: options.min,\n      writable: false\n    },\n    max: {\n      value: options.max,\n      writable: false\n    }\n  })\n\n\n\n  param._targets = targets\n  param._lastValue = options.defaultValue\n\n  // override proto-methods\n  param.setValueAtTime = setValueAtTime\n  param.linearRampToValueAtTime = linearRampToValueAtTime\n  param.exponentialRampToValueAtTime = exponentialRampToValueAtTime\n  param.setTargetAtTime = setTargetAtTime\n  param.setValueCurveAtTime = setValueCurveAtTime\n  param.cancelScheduledValues = cancelScheduledValues\n  param.addTarget = addTarget\n  param.clearTargets = clearTargets\n  param.context = audioContext\n\n  // get value between min and max\n  param.fence = fence\n  \n  // set initial value\n  if (options.defaultValue != null){\n    param.value = options.defaultValue\n  }\n\n  return param\n}\n\nfunction fence(value){\n  if (this.min != null){\n    value = Math.max(this.min, value)\n  }\n\n  if (this.max != null){\n    value = Math.min(this.max, value)\n\n  }\n  return value\n}\n\nfunction setValueAtTime(value, startTime){\n  var targets = this._targets\n  value = this.fence(value)\n\n  this._lastValue = value\n\n  for (var i=0,l=targets.length;i<l;i++){\n    targets[i].setValueAtTime(value, startTime)\n  }\n}\n\nfunction setTargetAtTime(value, startTime, timeConstant){\n  // this needs to be rewritten to use custom curve\n  var targets = this._targets\n  value = this.fence(value)\n  for (var i=0,l=targets.length;i<l;i++){\n    if (targets[i].setTargetAtTime){\n      targets[i].setTargetAtTime(value, startTime, timeConstant)\n    }\n  }\n}\n\nfunction linearRampToValueAtTime(value, endTime){\n  var targets = this._targets\n  value = this.fence(value)\n\n  this._lastValue = value\n\n  for (var i=0,l=targets.length;i<l;i++){\n    targets[i].linearRampToValueAtTime(value, endTime)\n  }\n}\n\nfunction exponentialRampToValueAtTime(value, endTime){\n  var targets = this._targets\n  value = this.fence(value)\n\n  this._lastValue = value\n\n  for (var i=0,l=targets.length;i<l;i++){\n    targets[i].exponentialRampToValueAtTime(value, endTime)\n  }\n}\n\nfunction setValueCurveAtTime(curve, startTime, duration){\n  var targets = this._targets\n  this._lastValue = curve[curve.length-1]\n\n  for (var i=0,l=targets.length;i<l;i++){\n    targets[i].setValueCurveAtTime(curve, startTime, duration)\n  }\n}\n\nfunction cancelScheduledValues(startTime){\n  var targets = this._targets\n  for (var i=0,l=targets.length;i<l;i++){\n    targets[i].cancelScheduledValues(startTime)\n  }\n}\n\nfunction clearTargets(){\n  this._targets = []\n}\n\nfunction addTarget(target){\n  this._targets.push(target)\n  if (this._lastValue != null){\n    target.value = this._lastValue\n  }\n}\n\n//# sourceURL=webpack://vad/../../node_modules/custom-audio-node/audio-param.js?");

/***/ }),

/***/ "../../node_modules/custom-audio-node/index.js":
/*!*****************************************************!*\
  !*** ../../node_modules/custom-audio-node/index.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var createAudioParam = __webpack_require__(/*! ./audio-param */ \"../../node_modules/custom-audio-node/audio-param.js\")\n\nmodule.exports = function(input, output, params, onDestinationChange){\n  var audioContext = (input || output).context\n\n  var node = audioContext.createGain()\n  node._onDestinationChange = onDestinationChange\n\n  if (input){\n    node.connect(input)\n  }\n\n  node._output = output\n  node._targetCount = 0\n\n  if (output){\n    node.connect = connect\n    node.disconnect = disconnect\n  }\n\n  addAudioParams(node, params)\n\n  return node\n}\n\nmodule.exports.createAudioParam = createAudioParam\n\nfunction connect(destination, channel){\n  this._targetCount += 1\n  this._output.connect(destination, channel)\n  if (typeof this._onDestinationChange === 'function'){\n    this._onDestinationChange(this._targetCount)\n  }\n}\n\nfunction disconnect(param){\n  this._targetCount = 0\n  this._output.disconnect(param)\n  if (typeof this._onDestinationChange === 'function'){\n    this._onDestinationChange(this._targetCount)\n  }\n}\n\nfunction addAudioParams(node, params){\n  if (params){\n    var keys = Object.keys(params)\n    for (var i=0,l=keys.length;i<l;i++){\n      var key = keys[i]\n      node[key] = createAudioParam(node.context, key, params[key])\n    }\n  }\n}\n\n//# sourceURL=webpack://vad/../../node_modules/custom-audio-node/index.js?");

/***/ }),

/***/ "../../node_modules/soundbank-pitch-shift/index.js":
/*!*********************************************************!*\
  !*** ../../node_modules/soundbank-pitch-shift/index.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var createAudioNode = __webpack_require__(/*! custom-audio-node */ \"../../node_modules/custom-audio-node/index.js\")\n\nmodule.exports = function PitchShift(audioContext){\n  var instance = new Jungle(audioContext)\n  var input = audioContext.createGain()\n  var wet = audioContext.createGain()\n  var dry = audioContext.createGain()\n  var output = audioContext.createGain()\n\n  dry.gain.value = 0\n\n  input.connect(wet)\n  input.connect(dry)\n\n  wet.connect(instance.input)\n  instance.output.connect(output)\n\n  dry.connect(output)\n\n  var node = createAudioNode(input, output, {\n    dry: {\n      min: 0, \n      defaultValue: 0,\n      target: dry.gain\n    },\n    wet: {\n      min: 0, \n      defaultValue: 1,\n      target: wet.gain\n    }\n  })\n\n  instance.setPitchOffset(getMultiplier(12))\n\n  var transpose = 0\n  Object.defineProperty(node, 'transpose', {\n    set: function(value){\n      transpose = getMultiplier(value)\n      instance.setPitchOffset(transpose)\n    },\n    get: function(){\n      return transpose\n    }\n  })\n  return node\n}\n\nfunction getMultiplier(x){\n\n  // don't ask...\n  if (x<0){\n    return x/12\n  } else {\n    var a5 = 1.8149080040913423e-7\n    var a4 = -0.000019413043101157434\n    var a3 = 0.0009795096626987743\n    var a2 = -0.014147877819596033\n    var a1 = 0.23005591195033048\n    var a0 = 0.02278153473118749\n\n    var x1 = x\n    var x2 = x*x\n    var x3 = x*x*x\n    var x4 = x*x*x*x\n    var x5 = x*x*x*x*x\n\n    return a0 + x1*a1 + x2*a2 + x3*a3 + x4*a4 + x5*a5\n  }\n\n}\n\n// include https://github.com/cwilso/Audio-Input-Effects/blob/master/js/jungle.js\n\n// Copyright 2012, Google Inc.\n// All rights reserved.\n// \n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions are\n// met:\n// \n//     * Redistributions of source code must retain the above copyright\n// notice, this list of conditions and the following disclaimer.\n//     * Redistributions in binary form must reproduce the above\n// copyright notice, this list of conditions and the following disclaimer\n// in the documentation and/or other materials provided with the\n// distribution.\n//     * Neither the name of Google Inc. nor the names of its\n// contributors may be used to endorse or promote products derived from\n// this software without specific prior written permission.\n// \n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nfunction createFadeBuffer(context, activeTime, fadeTime) {\n    var length1 = activeTime * context.sampleRate;\n    var length2 = (activeTime - 2*fadeTime) * context.sampleRate;\n    var length = length1 + length2;\n    var buffer = context.createBuffer(1, length, context.sampleRate);\n    var p = buffer.getChannelData(0);\n        \n    var fadeLength = fadeTime * context.sampleRate;\n\n    var fadeIndex1 = fadeLength;\n    var fadeIndex2 = length1 - fadeLength;\n    \n    // 1st part of cycle\n    for (var i = 0; i < length1; ++i) {\n        var value;\n        \n        if (i < fadeIndex1) {\n            value = Math.sqrt(i / fadeLength);\n        } else if (i >= fadeIndex2) {\n            value = Math.sqrt(1 - (i - fadeIndex2) / fadeLength);\n        } else {\n            value = 1;\n        }\n        \n        p[i] = value;\n    }\n\n    // 2nd part\n    for (var i = length1; i < length; ++i) {\n        p[i] = 0;\n    }\n    \n    \n    return buffer;\n}\n\nfunction createDelayTimeBuffer(context, activeTime, fadeTime, shiftUp) {\n    var length1 = activeTime * context.sampleRate;\n    var length2 = (activeTime - 2*fadeTime) * context.sampleRate;\n    var length = length1 + length2;\n    var buffer = context.createBuffer(1, length, context.sampleRate);\n    var p = buffer.getChannelData(0);\n    \n    // 1st part of cycle\n    for (var i = 0; i < length1; ++i) {\n        if (shiftUp)\n          // This line does shift-up transpose\n          p[i] = (length1-i)/length;\n        else\n          // This line does shift-down transpose\n          p[i] = i / length1;\n    }\n\n    // 2nd part\n    for (var i = length1; i < length; ++i) {\n        p[i] = 0;\n    }\n\n    return buffer;\n}\n\nvar delayTime = 0.100;\nvar fadeTime = 0.050;\nvar bufferTime = 0.100;\n\nfunction Jungle(context) {\n    this.context = context;\n    // Create nodes for the input and output of this \"module\".\n    var input = context.createGain();\n    var output = context.createGain();\n    this.input = input;\n    this.output = output;\n    \n    // Delay modulation.\n    var mod1 = context.createBufferSource();\n    var mod2 = context.createBufferSource();\n    var mod3 = context.createBufferSource();\n    var mod4 = context.createBufferSource();\n    this.shiftDownBuffer = createDelayTimeBuffer(context, bufferTime, fadeTime, false);\n    this.shiftUpBuffer = createDelayTimeBuffer(context, bufferTime, fadeTime, true);\n    mod1.buffer = this.shiftDownBuffer;\n    mod2.buffer = this.shiftDownBuffer;\n    mod3.buffer = this.shiftUpBuffer;\n    mod4.buffer = this.shiftUpBuffer;\n    mod1.loop = true;\n    mod2.loop = true;\n    mod3.loop = true;\n    mod4.loop = true;\n\n    // for switching between oct-up and oct-down\n    var mod1Gain = context.createGain();\n    var mod2Gain = context.createGain();\n    var mod3Gain = context.createGain();\n    mod3Gain.gain.value = 0;\n    var mod4Gain = context.createGain();\n    mod4Gain.gain.value = 0;\n\n    mod1.connect(mod1Gain);\n    mod2.connect(mod2Gain);\n    mod3.connect(mod3Gain);\n    mod4.connect(mod4Gain);\n\n    // Delay amount for changing pitch.\n    var modGain1 = context.createGain();\n    var modGain2 = context.createGain();\n\n    var delay1 = context.createDelay();\n    var delay2 = context.createDelay();\n    mod1Gain.connect(modGain1);\n    mod2Gain.connect(modGain2);\n    mod3Gain.connect(modGain1);\n    mod4Gain.connect(modGain2);\n    modGain1.connect(delay1.delayTime);\n    modGain2.connect(delay2.delayTime);\n\n    // Crossfading.\n    var fade1 = context.createBufferSource();\n    var fade2 = context.createBufferSource();\n    var fadeBuffer = createFadeBuffer(context, bufferTime, fadeTime);\n    fade1.buffer = fadeBuffer\n    fade2.buffer = fadeBuffer;\n    fade1.loop = true;\n    fade2.loop = true;\n\n    var mix1 = context.createGain();\n    var mix2 = context.createGain();\n    mix1.gain.value = 0;\n    mix2.gain.value = 0;\n\n    fade1.connect(mix1.gain);    \n    fade2.connect(mix2.gain);\n        \n    // Connect processing graph.\n    input.connect(delay1);\n    input.connect(delay2);    \n    delay1.connect(mix1);\n    delay2.connect(mix2);\n    mix1.connect(output);\n    mix2.connect(output);\n    \n    // Start\n    var t = context.currentTime + 0.050;\n    var t2 = t + bufferTime - fadeTime;\n    mod1.start(t);\n    mod2.start(t2);\n    mod3.start(t);\n    mod4.start(t2);\n    fade1.start(t);\n    fade2.start(t2);\n\n    this.mod1 = mod1;\n    this.mod2 = mod2;\n    this.mod1Gain = mod1Gain;\n    this.mod2Gain = mod2Gain;\n    this.mod3Gain = mod3Gain;\n    this.mod4Gain = mod4Gain;\n    this.modGain1 = modGain1;\n    this.modGain2 = modGain2;\n    this.fade1 = fade1;\n    this.fade2 = fade2;\n    this.mix1 = mix1;\n    this.mix2 = mix2;\n    this.delay1 = delay1;\n    this.delay2 = delay2;\n    \n    this.setDelay(delayTime);\n}\n\nJungle.prototype.setDelay = function(delayTime) {\n    this.modGain1.gain.setTargetAtTime(0.5*delayTime, 0, 0.010);\n    this.modGain2.gain.setTargetAtTime(0.5*delayTime, 0, 0.010);\n}\n\nJungle.prototype.setPitchOffset = function(mult) {\n  if (mult>0) { // pitch up\n    this.mod1Gain.gain.value = 0;\n    this.mod2Gain.gain.value = 0;\n    this.mod3Gain.gain.value = 1;\n    this.mod4Gain.gain.value = 1;\n  } else { // pitch down\n    this.mod1Gain.gain.value = 1;\n    this.mod2Gain.gain.value = 1;\n    this.mod3Gain.gain.value = 0;\n    this.mod4Gain.gain.value = 0;\n  }\n  this.setDelay(delayTime*Math.abs(mult));\n}\n\n//# sourceURL=webpack://vad/../../node_modules/soundbank-pitch-shift/index.js?");

/***/ }),

/***/ "./dist/_common/frame-processor.js":
/*!*****************************************!*\
  !*** ./dist/_common/frame-processor.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n/*\nSome of this code, together with the default options found in index.ts,\nwere taken (or took inspiration) from https://github.com/snakers4/silero-vad\n*/\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FrameProcessor = exports.validateOptions = exports.defaultFrameProcessorOptions = void 0;\nconst messages_1 = __webpack_require__(/*! ./messages */ \"./dist/_common/messages.js\");\nconst logging_1 = __webpack_require__(/*! ./logging */ \"./dist/_common/logging.js\");\nconst RECOMMENDED_FRAME_SAMPLES = [512, 1024, 1536];\nexports.defaultFrameProcessorOptions = {\n    positiveSpeechThreshold: 0.5,\n    negativeSpeechThreshold: 0.5 - 0.15,\n    preSpeechPadFrames: 1,\n    redemptionFrames: 8,\n    frameSamples: 1536,\n    minSpeechFrames: 3,\n    submitUserSpeechOnPause: false,\n};\nfunction validateOptions(options) {\n    if (!RECOMMENDED_FRAME_SAMPLES.includes(options.frameSamples)) {\n        logging_1.log.warn(\"You are using an unusual frame size\");\n    }\n    if (options.positiveSpeechThreshold < 0 ||\n        options.negativeSpeechThreshold > 1) {\n        logging_1.log.error(\"postiveSpeechThreshold should be a number between 0 and 1\");\n    }\n    if (options.negativeSpeechThreshold < 0 ||\n        options.negativeSpeechThreshold > options.positiveSpeechThreshold) {\n        logging_1.log.error(\"negativeSpeechThreshold should be between 0 and postiveSpeechThreshold\");\n    }\n    if (options.preSpeechPadFrames < 0) {\n        logging_1.log.error(\"preSpeechPadFrames should be positive\");\n    }\n    if (options.redemptionFrames < 0) {\n        logging_1.log.error(\"preSpeechPadFrames should be positive\");\n    }\n}\nexports.validateOptions = validateOptions;\nconst concatArrays = (arrays) => {\n    const sizes = arrays.reduce((out, next) => {\n        out.push(out.at(-1) + next.length);\n        return out;\n    }, [0]);\n    const outArray = new Float32Array(sizes.at(-1));\n    arrays.forEach((arr, index) => {\n        const place = sizes[index];\n        outArray.set(arr, place);\n    });\n    return outArray;\n};\nclass FrameProcessor {\n    constructor(modelProcessFunc, modelResetFunc, options) {\n        this.modelProcessFunc = modelProcessFunc;\n        this.modelResetFunc = modelResetFunc;\n        this.options = options;\n        this.speaking = false;\n        this.redemptionCounter = 0;\n        this.active = false;\n        this.reset = () => {\n            this.speaking = false;\n            this.audioBuffer = [];\n            this.modelResetFunc();\n            this.redemptionCounter = 0;\n        };\n        this.pause = () => {\n            this.active = false;\n            if (this.options.submitUserSpeechOnPause) {\n                return this.endSegment();\n            }\n            else {\n                this.reset();\n                return {};\n            }\n        };\n        this.resume = () => {\n            this.active = true;\n        };\n        this.endSegment = () => {\n            const audioBuffer = this.audioBuffer;\n            this.audioBuffer = [];\n            const speaking = this.speaking;\n            this.reset();\n            const speechFrameCount = audioBuffer.reduce((acc, item) => {\n                return acc + +item.isSpeech;\n            }, 0);\n            if (speaking) {\n                if (speechFrameCount >= this.options.minSpeechFrames) {\n                    const audio = concatArrays(audioBuffer.map((item) => item.frame));\n                    return { msg: messages_1.Message.SpeechEnd, audio };\n                }\n                else {\n                    return { msg: messages_1.Message.VADMisfire };\n                }\n            }\n            return {};\n        };\n        this.process = async (frame) => {\n            if (!this.active) {\n                return {};\n            }\n            const probs = await this.modelProcessFunc(frame);\n            this.audioBuffer.push({\n                frame,\n                isSpeech: probs.isSpeech >= this.options.positiveSpeechThreshold,\n            });\n            if (probs.isSpeech >= this.options.positiveSpeechThreshold &&\n                this.redemptionCounter) {\n                this.redemptionCounter = 0;\n            }\n            if (probs.isSpeech >= this.options.positiveSpeechThreshold &&\n                !this.speaking) {\n                this.speaking = true;\n                return { probs, msg: messages_1.Message.SpeechStart };\n            }\n            if (probs.isSpeech < this.options.negativeSpeechThreshold &&\n                this.speaking &&\n                ++this.redemptionCounter >= this.options.redemptionFrames) {\n                this.redemptionCounter = 0;\n                this.speaking = false;\n                const audioBuffer = this.audioBuffer;\n                this.audioBuffer = [];\n                const speechFrameCount = audioBuffer.reduce((acc, item) => {\n                    return acc + +item.isSpeech;\n                }, 0);\n                if (speechFrameCount >= this.options.minSpeechFrames) {\n                    const audio = concatArrays(audioBuffer.map((item) => item.frame));\n                    return { probs, msg: messages_1.Message.SpeechEnd, audio };\n                }\n                else {\n                    return { probs, msg: messages_1.Message.VADMisfire };\n                }\n            }\n            if (!this.speaking) {\n                while (this.audioBuffer.length > this.options.preSpeechPadFrames) {\n                    this.audioBuffer.shift();\n                }\n            }\n            return { probs };\n        };\n        this.audioBuffer = [];\n        this.reset();\n    }\n}\nexports.FrameProcessor = FrameProcessor;\n//# sourceMappingURL=frame-processor.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/frame-processor.js?");

/***/ }),

/***/ "./dist/_common/index.js":
/*!*******************************!*\
  !*** ./dist/_common/index.js ***!
  \*******************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.utils = void 0;\nconst _utils = __importStar(__webpack_require__(/*! ./utils */ \"./dist/_common/utils.js\"));\nexports.utils = {\n    minFramesForTargetMS: _utils.minFramesForTargetMS,\n    arrayBufferToBase64: _utils.arrayBufferToBase64,\n    encodeWAV: _utils.encodeWAV,\n};\n__exportStar(__webpack_require__(/*! ./non-real-time-vad */ \"./dist/_common/non-real-time-vad.js\"), exports);\n__exportStar(__webpack_require__(/*! ./frame-processor */ \"./dist/_common/frame-processor.js\"), exports);\n__exportStar(__webpack_require__(/*! ./messages */ \"./dist/_common/messages.js\"), exports);\n__exportStar(__webpack_require__(/*! ./logging */ \"./dist/_common/logging.js\"), exports);\n__exportStar(__webpack_require__(/*! ./models */ \"./dist/_common/models.js\"), exports);\n__exportStar(__webpack_require__(/*! ./resampler */ \"./dist/_common/resampler.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/index.js?");

/***/ }),

/***/ "./dist/_common/logging.js":
/*!*********************************!*\
  !*** ./dist/_common/logging.js ***!
  \*********************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.log = exports.LOG_PREFIX = void 0;\nexports.LOG_PREFIX = \"[VAD]\";\nconst levels = [\"error\", \"debug\", \"warn\"];\nfunction getLog(level) {\n    return (...args) => {\n        console[level](exports.LOG_PREFIX, ...args);\n    };\n}\nconst _log = levels.reduce((acc, level) => {\n    acc[level] = getLog(level);\n    return acc;\n}, {});\nexports.log = _log;\n//# sourceMappingURL=logging.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/logging.js?");

/***/ }),

/***/ "./dist/_common/messages.js":
/*!**********************************!*\
  !*** ./dist/_common/messages.js ***!
  \**********************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Message = void 0;\nvar Message;\n(function (Message) {\n    Message[\"AudioFrame\"] = \"AUDIO_FRAME\";\n    Message[\"SpeechStart\"] = \"SPEECH_START\";\n    Message[\"VADMisfire\"] = \"VAD_MISFIRE\";\n    Message[\"SpeechEnd\"] = \"SPEECH_END\";\n    Message[\"SpeechStop\"] = \"SPEECH_STOP\";\n})(Message || (exports.Message = Message = {}));\n//# sourceMappingURL=messages.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/messages.js?");

/***/ }),

/***/ "./dist/_common/models.js":
/*!********************************!*\
  !*** ./dist/_common/models.js ***!
  \********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Silero = void 0;\n// @ts-ignore\nconst logging_1 = __webpack_require__(/*! ./logging */ \"./dist/_common/logging.js\");\nclass Silero {\n    constructor(ort, modelFetcher) {\n        this.ort = ort;\n        this.modelFetcher = modelFetcher;\n        this.init = async () => {\n            logging_1.log.debug(\"initializing vad\");\n            const modelArrayBuffer = await this.modelFetcher();\n            this._session = await this.ort.InferenceSession.create(modelArrayBuffer);\n            this._sr = new this.ort.Tensor(\"int64\", [16000n]);\n            this.reset_state();\n            logging_1.log.debug(\"vad is initialized\");\n        };\n        this.reset_state = () => {\n            const zeroes = Array(2 * 64).fill(0);\n            this._h = new this.ort.Tensor(\"float32\", zeroes, [2, 1, 64]);\n            this._c = new this.ort.Tensor(\"float32\", zeroes, [2, 1, 64]);\n        };\n        this.process = async (audioFrame) => {\n            const t = new this.ort.Tensor(\"float32\", audioFrame, [1, audioFrame.length]);\n            const inputs = {\n                input: t,\n                h: this._h,\n                c: this._c,\n                sr: this._sr,\n            };\n            const out = await this._session.run(inputs);\n            this._h = out.hn;\n            this._c = out.cn;\n            const [isSpeech] = out.output.data;\n            const notSpeech = 1 - isSpeech;\n            return { notSpeech, isSpeech };\n        };\n    }\n}\nexports.Silero = Silero;\n_a = Silero;\nSilero.new = async (ort, modelFetcher) => {\n    const model = new _a(ort, modelFetcher);\n    await model.init();\n    return model;\n};\n//# sourceMappingURL=models.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/models.js?");

/***/ }),

/***/ "./dist/_common/non-real-time-vad.js":
/*!*******************************************!*\
  !*** ./dist/_common/non-real-time-vad.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PlatformAgnosticNonRealTimeVAD = exports.defaultNonRealTimeVADOptions = void 0;\nconst frame_processor_1 = __webpack_require__(/*! ./frame-processor */ \"./dist/_common/frame-processor.js\");\nconst messages_1 = __webpack_require__(/*! ./messages */ \"./dist/_common/messages.js\");\nconst models_1 = __webpack_require__(/*! ./models */ \"./dist/_common/models.js\");\nconst resampler_1 = __webpack_require__(/*! ./resampler */ \"./dist/_common/resampler.js\");\nexports.defaultNonRealTimeVADOptions = {\n    ...frame_processor_1.defaultFrameProcessorOptions,\n};\nclass PlatformAgnosticNonRealTimeVAD {\n    static async _new(modelFetcher, ort, options = {}) {\n        const vad = new this(modelFetcher, ort, {\n            ...exports.defaultNonRealTimeVADOptions,\n            ...options,\n        });\n        await vad.init();\n        return vad;\n    }\n    constructor(modelFetcher, ort, options) {\n        this.modelFetcher = modelFetcher;\n        this.ort = ort;\n        this.options = options;\n        this.init = async () => {\n            const model = await models_1.Silero.new(this.ort, this.modelFetcher);\n            this.frameProcessor = new frame_processor_1.FrameProcessor(model.process, model.reset_state, {\n                frameSamples: this.options.frameSamples,\n                positiveSpeechThreshold: this.options.positiveSpeechThreshold,\n                negativeSpeechThreshold: this.options.negativeSpeechThreshold,\n                redemptionFrames: this.options.redemptionFrames,\n                preSpeechPadFrames: this.options.preSpeechPadFrames,\n                minSpeechFrames: this.options.minSpeechFrames,\n                submitUserSpeechOnPause: this.options.submitUserSpeechOnPause,\n            });\n            this.frameProcessor.resume();\n        };\n        this.run = async function* (inputAudio, sampleRate) {\n            const resamplerOptions = {\n                nativeSampleRate: sampleRate,\n                targetSampleRate: 16000,\n                targetFrameSize: this.options.frameSamples,\n                targetSpeed: 1,\n            };\n            const resampler = new resampler_1.Resampler(resamplerOptions);\n            const frames = resampler.process(inputAudio);\n            let start, end;\n            for (const i of [...Array(frames.length)].keys()) {\n                const f = frames[i];\n                const { msg, audio } = await this.frameProcessor.process(f);\n                switch (msg) {\n                    case messages_1.Message.SpeechStart:\n                        start = (i * this.options.frameSamples) / 16;\n                        break;\n                    case messages_1.Message.SpeechEnd:\n                        end = ((i + 1) * this.options.frameSamples) / 16;\n                        // @ts-ignore\n                        yield { audio, start, end };\n                        break;\n                    default:\n                        break;\n                }\n            }\n            const { msg, audio } = this.frameProcessor.endSegment();\n            if (msg == messages_1.Message.SpeechEnd) {\n                yield {\n                    audio,\n                    // @ts-ignore\n                    start,\n                    end: (frames.length * this.options.frameSamples) / 16,\n                };\n            }\n        };\n        (0, frame_processor_1.validateOptions)(options);\n    }\n}\nexports.PlatformAgnosticNonRealTimeVAD = PlatformAgnosticNonRealTimeVAD;\n//# sourceMappingURL=non-real-time-vad.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/non-real-time-vad.js?");

/***/ }),

/***/ "./dist/_common/resampler.js":
/*!***********************************!*\
  !*** ./dist/_common/resampler.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Resampler = void 0;\nconst logging_1 = __webpack_require__(/*! ./logging */ \"./dist/_common/logging.js\");\nclass Resampler {\n    constructor(options) {\n        this.options = options;\n        this.process = (audioFrame) => {\n            const outputFrames = [];\n            for (const sample of audioFrame) {\n                this.inputBuffer.push(sample);\n            }\n            while ((this.inputBuffer.length * this.options.targetSampleRate * this.options.targetSpeed) /\n                this.options.nativeSampleRate >\n                this.options.targetFrameSize) {\n                const outputFrame = new Float32Array(this.options.targetFrameSize);\n                let outputIndex = 0;\n                let inputIndex = 0;\n                while (outputIndex < this.options.targetFrameSize) {\n                    let sum = 0;\n                    let num = 0;\n                    while (inputIndex <\n                        Math.min(this.inputBuffer.length, ((outputIndex + 1) * this.options.nativeSampleRate) /\n                            (this.options.targetSampleRate * this.options.targetSpeed))) {\n                        sum += this.inputBuffer[inputIndex];\n                        num++;\n                        inputIndex++;\n                    }\n                    outputFrame[outputIndex] = sum / num;\n                    outputIndex++;\n                }\n                this.inputBuffer = this.inputBuffer.slice(inputIndex);\n                outputFrames.push(outputFrame);\n            }\n            return outputFrames;\n        };\n        if (options.nativeSampleRate < 16000) {\n            logging_1.log.error(\"nativeSampleRate is too low. Should have 16000 = targetSampleRate <= nativeSampleRate\");\n        }\n        this.inputBuffer = [];\n    }\n}\nexports.Resampler = Resampler;\n//# sourceMappingURL=resampler.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/resampler.js?");

/***/ }),

/***/ "./dist/_common/utils.js":
/*!*******************************!*\
  !*** ./dist/_common/utils.js ***!
  \*******************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.encodeWAV = exports.arrayBufferToBase64 = exports.minFramesForTargetMS = void 0;\nfunction minFramesForTargetMS(targetDuration, frameSamples, sr = 16000) {\n    return Math.ceil((targetDuration * sr) / 1000 / frameSamples);\n}\nexports.minFramesForTargetMS = minFramesForTargetMS;\nfunction arrayBufferToBase64(buffer) {\n    var binary = \"\";\n    var bytes = new Uint8Array(buffer);\n    var len = bytes.byteLength;\n    for (var i = 0; i < len; i++) {\n        binary += String.fromCharCode(bytes[i]);\n    }\n    return btoa(binary);\n}\nexports.arrayBufferToBase64 = arrayBufferToBase64;\n/*\nThis rest of this was mostly copied from https://github.com/linto-ai/WebVoiceSDK\n*/\nfunction encodeWAV(samples, format = 3, sampleRate = 16000, numChannels = 1, bitDepth = 32) {\n    var bytesPerSample = bitDepth / 8;\n    var blockAlign = numChannels * bytesPerSample;\n    var buffer = new ArrayBuffer(44 + samples.length * bytesPerSample);\n    var view = new DataView(buffer);\n    /* RIFF identifier */\n    writeString(view, 0, \"RIFF\");\n    /* RIFF chunk length */\n    view.setUint32(4, 36 + samples.length * bytesPerSample, true);\n    /* RIFF type */\n    writeString(view, 8, \"WAVE\");\n    /* format chunk identifier */\n    writeString(view, 12, \"fmt \");\n    /* format chunk length */\n    view.setUint32(16, 16, true);\n    /* sample format (raw) */\n    view.setUint16(20, format, true);\n    /* channel count */\n    view.setUint16(22, numChannels, true);\n    /* sample rate */\n    view.setUint32(24, sampleRate, true);\n    /* byte rate (sample rate * block align) */\n    view.setUint32(28, sampleRate * blockAlign, true);\n    /* block align (channel count * bytes per sample) */\n    view.setUint16(32, blockAlign, true);\n    /* bits per sample */\n    view.setUint16(34, bitDepth, true);\n    /* data chunk identifier */\n    writeString(view, 36, \"data\");\n    /* data chunk length */\n    view.setUint32(40, samples.length * bytesPerSample, true);\n    if (format === 1) {\n        // Raw PCM\n        floatTo16BitPCM(view, 44, samples);\n    }\n    else {\n        writeFloat32(view, 44, samples);\n    }\n    return buffer;\n}\nexports.encodeWAV = encodeWAV;\nfunction interleave(inputL, inputR) {\n    var length = inputL.length + inputR.length;\n    var result = new Float32Array(length);\n    var index = 0;\n    var inputIndex = 0;\n    while (index < length) {\n        result[index++] = inputL[inputIndex];\n        result[index++] = inputR[inputIndex];\n        inputIndex++;\n    }\n    return result;\n}\nfunction writeFloat32(output, offset, input) {\n    for (var i = 0; i < input.length; i++, offset += 4) {\n        output.setFloat32(offset, input[i], true);\n    }\n}\nfunction floatTo16BitPCM(output, offset, input) {\n    for (var i = 0; i < input.length; i++, offset += 2) {\n        var s = Math.max(-1, Math.min(1, input[i]));\n        output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n    }\n}\nfunction writeString(view, offset, string) {\n    for (var i = 0; i < string.length; i++) {\n        view.setUint8(offset + i, string.charCodeAt(i));\n    }\n}\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://vad/./dist/_common/utils.js?");

/***/ }),

/***/ "./dist/asset-path.js":
/*!****************************!*\
  !*** ./dist/asset-path.js ***!
  \****************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.assetPath = void 0;\n// nextjs@14 bundler may attempt to execute this during SSR and crash\nconst isWeb = typeof window !== \"undefined\" && typeof window.document !== \"undefined\";\nconst currentScript = isWeb\n    ? window.document.currentScript\n    : null;\nlet basePath = \"\";\nif (currentScript) {\n    basePath = currentScript.src\n        .replace(/#.*$/, \"\")\n        .replace(/\\?.*$/, \"\")\n        .replace(/\\/[^\\/]+$/, \"/\");\n}\nconst assetPath = (file) => {\n    return basePath + file;\n};\nexports.assetPath = assetPath;\n//# sourceMappingURL=asset-path.js.map\n\n//# sourceURL=webpack://vad/./dist/asset-path.js?");

/***/ }),

/***/ "./dist/default-model-fetcher.js":
/*!***************************************!*\
  !*** ./dist/default-model-fetcher.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defaultModelFetcher = void 0;\nconst defaultModelFetcher = (path) => {\n    return fetch(path).then((model) => model.arrayBuffer());\n};\nexports.defaultModelFetcher = defaultModelFetcher;\n//# sourceMappingURL=default-model-fetcher.js.map\n\n//# sourceURL=webpack://vad/./dist/default-model-fetcher.js?");

/***/ }),

/***/ "./dist/index.js":
/*!***********************!*\
  !*** ./dist/index.js ***!
  \***********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defaultRealTimeVADOptions = exports.AudioNodeVAD = exports.MicVAD = exports.NonRealTimeVAD = exports.Message = exports.FrameProcessor = exports.utils = exports.defaultNonRealTimeVADOptions = void 0;\nconst ort = __importStar(__webpack_require__(/*! onnxruntime-web */ \"onnxruntime-web\"));\nconst _common_1 = __webpack_require__(/*! ./_common */ \"./dist/_common/index.js\");\nObject.defineProperty(exports, \"FrameProcessor\", ({ enumerable: true, get: function () { return _common_1.FrameProcessor; } }));\nObject.defineProperty(exports, \"Message\", ({ enumerable: true, get: function () { return _common_1.Message; } }));\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./dist/utils.js\");\nconst default_model_fetcher_1 = __webpack_require__(/*! ./default-model-fetcher */ \"./dist/default-model-fetcher.js\");\nconst asset_path_1 = __webpack_require__(/*! ./asset-path */ \"./dist/asset-path.js\");\nexports.defaultNonRealTimeVADOptions = {\n    modelURL: (0, asset_path_1.assetPath)(\"silero_vad.onnx\"),\n    modelFetcher: default_model_fetcher_1.defaultModelFetcher,\n};\nclass NonRealTimeVAD extends _common_1.PlatformAgnosticNonRealTimeVAD {\n    static async new(options = {}) {\n        const { modelURL, modelFetcher } = {\n            ...exports.defaultNonRealTimeVADOptions,\n            ...options,\n        };\n        return await this._new(() => modelFetcher(modelURL), ort, options);\n    }\n}\nexports.NonRealTimeVAD = NonRealTimeVAD;\nexports.utils = { audioFileToArray: utils_1.audioFileToArray, ..._common_1.utils };\nvar real_time_vad_1 = __webpack_require__(/*! ./real-time-vad */ \"./dist/real-time-vad.js\");\nObject.defineProperty(exports, \"MicVAD\", ({ enumerable: true, get: function () { return real_time_vad_1.MicVAD; } }));\nObject.defineProperty(exports, \"AudioNodeVAD\", ({ enumerable: true, get: function () { return real_time_vad_1.AudioNodeVAD; } }));\nObject.defineProperty(exports, \"defaultRealTimeVADOptions\", ({ enumerable: true, get: function () { return real_time_vad_1.defaultRealTimeVADOptions; } }));\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://vad/./dist/index.js?");

/***/ }),

/***/ "./dist/real-time-vad.js":
/*!*******************************!*\
  !*** ./dist/real-time-vad.js ***!
  \*******************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AudioNodeVAD = exports.MicVAD = exports.defaultRealTimeVADOptions = void 0;\nconst ort = __importStar(__webpack_require__(/*! onnxruntime-web */ \"onnxruntime-web\"));\nconst soundbank_pitch_shift_1 = __webpack_require__(/*! soundbank-pitch-shift */ \"../../node_modules/soundbank-pitch-shift/index.js\");\nconst _common_1 = __webpack_require__(/*! ./_common */ \"./dist/_common/index.js\");\nconst asset_path_1 = __webpack_require__(/*! ./asset-path */ \"./dist/asset-path.js\");\nconst default_model_fetcher_1 = __webpack_require__(/*! ./default-model-fetcher */ \"./dist/default-model-fetcher.js\");\nexports.defaultRealTimeVADOptions = {\n    ..._common_1.defaultFrameProcessorOptions,\n    onFrameProcessed: (probabilities) => { },\n    onVADMisfire: () => {\n        _common_1.log.debug(\"VAD misfire\");\n    },\n    onSpeechStart: () => {\n        _common_1.log.debug(\"Detected speech start\");\n    },\n    onSpeechEnd: () => {\n        _common_1.log.debug(\"Detected speech end\");\n    },\n    workletURL: (0, asset_path_1.assetPath)(\"vad.worklet.bundle.min.js\"),\n    modelURL: (0, asset_path_1.assetPath)(\"silero_vad.onnx\"),\n    modelFetcher: default_model_fetcher_1.defaultModelFetcher,\n    stream: undefined,\n};\nclass MicVAD {\n    static async new(options = {}) {\n        const fullOptions = {\n            ...exports.defaultRealTimeVADOptions,\n            ...options,\n        };\n        (0, _common_1.validateOptions)(fullOptions);\n        let stream;\n        if (fullOptions.stream === undefined)\n            stream = await navigator.mediaDevices.getUserMedia({\n                audio: {\n                    ...fullOptions.additionalAudioConstraints,\n                    channelCount: 1,\n                    echoCancellation: true,\n                    autoGainControl: true,\n                    noiseSuppression: true,\n                },\n            });\n        else\n            stream = fullOptions.stream;\n        const audioContext = new AudioContext();\n        const sourceNode = new MediaStreamAudioSourceNode(audioContext, {\n            mediaStream: stream,\n        });\n        const audioNodeVAD = await AudioNodeVAD.new(audioContext, fullOptions);\n        audioNodeVAD.receive(sourceNode);\n        return new MicVAD(fullOptions, audioContext, stream, audioNodeVAD, sourceNode);\n    }\n    constructor(options, audioContext, stream, audioNodeVAD, sourceNode, listening = false) {\n        this.options = options;\n        this.audioContext = audioContext;\n        this.stream = stream;\n        this.audioNodeVAD = audioNodeVAD;\n        this.sourceNode = sourceNode;\n        this.listening = listening;\n        this.pause = () => {\n            this.audioNodeVAD.pause();\n            this.listening = false;\n        };\n        this.start = () => {\n            this.audioNodeVAD.start();\n            this.listening = true;\n        };\n        this.destroy = () => {\n            if (this.listening) {\n                this.pause();\n            }\n            if (this.options.stream === undefined) {\n                this.stream.getTracks().forEach((track) => track.stop());\n            }\n            this.sourceNode.disconnect();\n            this.audioNodeVAD.destroy();\n            this.audioContext.close();\n        };\n    }\n}\nexports.MicVAD = MicVAD;\nclass AudioNodeVAD {\n    static async new(ctx, options = {}) {\n        const fullOptions = {\n            ...exports.defaultRealTimeVADOptions,\n            ...options,\n        };\n        (0, _common_1.validateOptions)(fullOptions);\n        await ctx.audioWorklet.addModule(fullOptions.workletURL);\n        const vadNode = new AudioWorkletNode(ctx, \"vad-helper-worklet\", {\n            processorOptions: {\n                frameSamples: fullOptions.frameSamples,\n            },\n            parameterData: {\n                audioSpeed: 1,\n            },\n        });\n        const model = await _common_1.Silero.new(ort, () => fullOptions.modelFetcher(fullOptions.modelURL));\n        const frameProcessor = new _common_1.FrameProcessor(model.process, model.reset_state, {\n            frameSamples: fullOptions.frameSamples,\n            positiveSpeechThreshold: fullOptions.positiveSpeechThreshold,\n            negativeSpeechThreshold: fullOptions.negativeSpeechThreshold,\n            redemptionFrames: fullOptions.redemptionFrames,\n            preSpeechPadFrames: fullOptions.preSpeechPadFrames,\n            minSpeechFrames: fullOptions.minSpeechFrames,\n            submitUserSpeechOnPause: fullOptions.submitUserSpeechOnPause,\n        });\n        const pitchShift = (0, soundbank_pitch_shift_1.PitchShift)(ctx);\n        const audioNodeVAD = new AudioNodeVAD(ctx, fullOptions, frameProcessor, vadNode, pitchShift);\n        vadNode.port.onmessage = async (ev) => {\n            switch (ev.data?.message) {\n                case _common_1.Message.AudioFrame:\n                    const buffer = ev.data.data;\n                    const frame = new Float32Array(buffer);\n                    await audioNodeVAD.processFrame(frame);\n                    break;\n                default:\n                    break;\n            }\n        };\n        return audioNodeVAD;\n    }\n    constructor(ctx, options, frameProcessor, entryNode, pitchShift) {\n        this.ctx = ctx;\n        this.options = options;\n        this.frameProcessor = frameProcessor;\n        this.entryNode = entryNode;\n        this.pitchShift = pitchShift;\n        this.pause = () => {\n            const ev = this.frameProcessor.pause();\n            this.handleFrameProcessorEvent(ev);\n        };\n        this.start = () => {\n            this.frameProcessor.resume();\n        };\n        this.receive = (node) => {\n            node.connect(this.pitchShift);\n            this.pitchShift.connect(this.entryNode);\n        };\n        this.updateAudioSpeed = (speed) => {\n            let cappedSpeed = Math.min(speed, 2);\n            this.entryNode.parameters.get('audioSpeed')?.setValueAtTime(cappedSpeed, this.ctx.currentTime);\n            this.pitchShift.transpose = 12 * Math.log2(cappedSpeed);\n            console.log(\"Changed audioSpeed real-time-vad.ts: \", this.entryNode.parameters.get('audioSpeed'));\n        };\n        this.processFrame = async (frame) => {\n            const ev = await this.frameProcessor.process(frame);\n            this.handleFrameProcessorEvent(ev);\n        };\n        this.handleFrameProcessorEvent = (ev) => {\n            if (ev.probs !== undefined) {\n                this.options.onFrameProcessed(ev.probs);\n            }\n            switch (ev.msg) {\n                case _common_1.Message.SpeechStart:\n                    this.options.onSpeechStart();\n                    break;\n                case _common_1.Message.VADMisfire:\n                    this.options.onVADMisfire();\n                    break;\n                case _common_1.Message.SpeechEnd:\n                    this.options.onSpeechEnd(ev.audio);\n                    break;\n                default:\n                    break;\n            }\n        };\n        this.destroy = () => {\n            this.entryNode.port.postMessage({\n                message: _common_1.Message.SpeechStop,\n            });\n            this.entryNode.disconnect();\n        };\n    }\n}\nexports.AudioNodeVAD = AudioNodeVAD;\n//# sourceMappingURL=real-time-vad.js.map\n\n//# sourceURL=webpack://vad/./dist/real-time-vad.js?");

/***/ }),

/***/ "./dist/utils.js":
/*!***********************!*\
  !*** ./dist/utils.js ***!
  \***********************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.audioFileToArray = void 0;\nasync function audioFileToArray(audioFileData) {\n    const ctx = new OfflineAudioContext(1, 1, 44100);\n    const reader = new FileReader();\n    let audioBuffer = null;\n    await new Promise((res) => {\n        reader.addEventListener(\"loadend\", (ev) => {\n            const audioData = reader.result;\n            ctx.decodeAudioData(audioData, (buffer) => {\n                audioBuffer = buffer;\n                ctx\n                    .startRendering()\n                    .then((renderedBuffer) => {\n                    console.log(\"Rendering completed successfully\");\n                    res();\n                })\n                    .catch((err) => {\n                    console.error(`Rendering failed: ${err}`);\n                });\n            }, (e) => {\n                console.log(`Error with decoding audio data: ${e}`);\n            });\n        });\n        reader.readAsArrayBuffer(audioFileData);\n    });\n    if (audioBuffer === null) {\n        throw Error(\"some shit\");\n    }\n    let _audioBuffer = audioBuffer;\n    let out = new Float32Array(_audioBuffer.length);\n    for (let i = 0; i < _audioBuffer.length; i++) {\n        for (let j = 0; j < _audioBuffer.numberOfChannels; j++) {\n            // @ts-ignore\n            out[i] += _audioBuffer.getChannelData(j)[i];\n        }\n    }\n    return { audio: out, sampleRate: _audioBuffer.sampleRate };\n}\nexports.audioFileToArray = audioFileToArray;\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://vad/./dist/utils.js?");

/***/ }),

/***/ "onnxruntime-web":
/*!******************************************************************************************************************!*\
  !*** external {"commonjs":"onnxruntime-web","commonjs2":"onnxruntime-web","amd":"onnxruntime-web","root":"ort"} ***!
  \******************************************************************************************************************/
/***/ ((module) => {

"use strict";
module.exports = __WEBPACK_EXTERNAL_MODULE_onnxruntime_web__;

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module is referenced by other modules so it can't be inlined
/******/ 	var __webpack_exports__ = __webpack_require__("./dist/index.js");
/******/ 	
/******/ 	return __webpack_exports__;
/******/ })()
;
});